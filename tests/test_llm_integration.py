"""
LLMçµ±åˆã®ãƒ†ã‚¹ãƒˆ

Phase 1ã®å‹•ä½œç¢ºèª:
- è¨­å®šã®èª­ã¿è¾¼ã¿
- LLMInterfaceã®åˆæœŸåŒ–
- ç°¡å˜ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ„æ€æ±ºå®š
"""

import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv

from src.agents.base_agent import BaseAgent, load_prompt_template
from src.llm.llm_interface import LLMInterface
from src.utils.config import get_api_key
from src.utils.logger import setup_logger


class TestHouseholdAgent(BaseAgent):
    """ãƒ†ã‚¹ãƒˆç”¨ã®ç°¡å˜ãªå®¶è¨ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""

    def __init__(self, agent_id: str, llm_interface: LLMInterface):
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®èª­ã¿è¾¼ã¿
        prompt_path = project_root / "src/llm/prompts/household_system.txt"
        system_prompt = load_prompt_template(prompt_path)

        super().__init__(
            agent_id=agent_id,
            agent_type="household",
            llm_interface=llm_interface,
            system_prompt=system_prompt,
            memory_size=3,
        )

        # ãƒ†ã‚¹ãƒˆç”¨ã®ç°¡å˜ãªå±æ€§
        self.attributes = {
            "name": "Test Family",
            "age": 35,
            "education": "college",
            "savings": 10000,
            "monthly_income": 3000,
            "employed": True,
        }

    def get_profile_str(self) -> str:
        return f"""Name: {self.attributes['name']}
Age: {self.attributes['age']}
Education: {self.attributes['education']}
Current Savings: ${self.attributes['savings']:,.0f}
Monthly Income: ${self.attributes['monthly_income']:,.0f}
Employment Status: {'Employed' if self.attributes['employed'] else 'Unemployed'}
"""

    def get_available_actions(self):
        """ç°¡ç•¥åŒ–ã•ã‚ŒãŸè¡Œå‹•ã‚»ãƒƒãƒˆ"""
        return [
            {
                "name": "purchase_goods",
                "description": "Purchase goods from the market",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "good_type": {
                            "type": "string",
                            "enum": ["food", "clothing", "electronics"],
                            "description": "Type of good to purchase",
                        },
                        "quantity": {
                            "type": "integer",
                            "minimum": 1,
                            "maximum": 100,
                            "description": "Quantity to purchase",
                        },
                    },
                    "required": ["good_type", "quantity"],
                },
            },
            {
                "name": "save_money",
                "description": "Save money in the bank",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "amount": {
                            "type": "number",
                            "minimum": 0,
                            "description": "Amount to save",
                        }
                    },
                    "required": ["amount"],
                },
            },
            {
                "name": "do_nothing",
                "description": "Take no action this period",
                "parameters": {"type": "object", "properties": {}},
            },
        ]

    def _get_fallback_action(self, observation):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¡Œå‹•: ä½•ã‚‚ã—ãªã„"""
        return {"function_name": "do_nothing", "arguments": {}}


def test_llm_interface():
    """LLMInterfaceã®åŸºæœ¬ãƒ†ã‚¹ãƒˆ"""
    print("\n=== LLMInterface Test ===")

    # ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
    load_dotenv()

    try:
        api_key = get_api_key()
    except ValueError as e:
        print(f"âŒ Error: {e}")
        print(
            "\n.envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„:"
        )
        print("  cp .env.example .env")
        print("  # .envã‚’ç·¨é›†ã—ã¦APIã‚­ãƒ¼ã‚’è¿½åŠ ")
        return False

    # LLMInterfaceã®åˆæœŸåŒ–
    llm = LLMInterface(
        api_key=api_key,
        model="gpt-4o-mini",
        temperature=0.7,
        max_tokens=500,
    )

    # ç°¡å˜ãªFunction Calling
    functions = [
        {
            "name": "get_weather",
            "description": "Get the current weather",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {"type": "string", "description": "City name"}
                },
                "required": ["location"],
            },
        }
    ]

    try:
        response = llm.function_call(
            system_prompt="You are a helpful assistant.",
            user_prompt="What's the weather like in Tokyo?",
            functions=functions,
        )

        print(f"âœ“ Function called: {response['function_name']}")
        print(f"âœ“ Arguments: {response['arguments']}")

        # ã‚³ã‚¹ãƒˆç¢ºèª
        cost = llm.get_cost_summary()
        print(f"âœ“ Cost: ${cost['estimated_cost_usd']:.4f}")

        return True

    except Exception as e:
        print(f"âŒ LLM call failed: {e}")
        return False


def test_agent_decision():
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ„æ€æ±ºå®šãƒ†ã‚¹ãƒˆ"""
    print("\n=== Agent Decision Test ===")

    # ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
    load_dotenv()

    try:
        api_key = get_api_key()
    except ValueError as e:
        print(f"âŒ Error: {e}")
        return False

    # LLMã¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–
    llm = LLMInterface(
        api_key=api_key,
        model="gpt-4o-mini",
        temperature=0.7,
    )

    agent = TestHouseholdAgent(agent_id="test_household_001", llm_interface=llm)

    # è¦³å¯Ÿæƒ…å ±ï¼ˆç°¡ç•¥ç‰ˆï¼‰
    observation = {
        "step": 1,
        "available_goods": ["food", "clothing", "electronics"],
        "prices": {"food": 50, "clothing": 100, "electronics": 500},
        "your_budget": agent.attributes["savings"] + agent.attributes["monthly_income"],
    }

    try:
        # è¡Œå‹•æ±ºå®š
        action = agent.decide_action(observation, step=1)

        print(f"âœ“ Agent decided: {action['function_name']}")
        print(f"âœ“ Arguments: {action['arguments']}")

        # çµæœã‚’è¨˜éŒ²
        agent.record_action_result("Success")

        # ã‚³ã‚¹ãƒˆç¢ºèª
        cost = llm.get_cost_summary()
        print(f"âœ“ Total cost so far: ${cost['estimated_cost_usd']:.4f}")

        return True

    except Exception as e:
        print(f"âŒ Agent decision failed: {e}")
        import traceback

        traceback.print_exc()
        return False


def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("=" * 60)
    print("SimCity Phase 1 Integration Test")
    print("=" * 60)

    # ãƒ­ã‚¬ãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    setup_logger(log_level="INFO", enable_console=True)

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_results = []

    # Test 1: LLMInterface
    test_results.append(("LLMInterface", test_llm_interface()))

    # Test 2: Agent Decision
    test_results.append(("Agent Decision", test_agent_decision()))

    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("Test Results Summary")
    print("=" * 60)

    for test_name, result in test_results:
        status = "âœ“ PASS" if result else "âŒ FAIL"
        print(f"{test_name}: {status}")

    all_passed = all(result for _, result in test_results)

    if all_passed:
        print("\nğŸ‰ All tests passed! Phase 1 integration is working.")
        print("\nNext steps:")
        print("  1. Proceed to Phase 2: Agent implementation")
        print("  2. Implement HouseholdAgent, FirmAgent, etc.")
    else:
        print("\nâš ï¸  Some tests failed. Please check the errors above.")

    return all_passed


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
